{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from config.config import BASE_PATH, PATH_TO_PATH_CONFIG_FILE\n",
    "from src.utils import load_paths_from_yaml, replace_base_path\n",
    "from src.modeling.encodings import convert_aspect_to_cardinal_direction, convert_canopy_cover_to_classes, convert_ffmc_to_classes\n",
    "from src.modeling.bayesian_models import (create_model_ffmc_adjustment_aspect, \n",
    "                                          create_model_ffmc_adjustment_foresttype,\n",
    "                                          create_model_ffmc_adjustment_canopy_cover)\n",
    "from src.modeling.utils import temporal_train_test_split, save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = load_paths_from_yaml(PATH_TO_PATH_CONFIG_FILE)\n",
    "paths = replace_base_path(paths, BASE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training data\n",
    "train_data = gpd.read_file(paths[\"training_data\"])\n",
    "train_data = train_data.loc[:, [\"ffmc\", \"aspect\", \"foresttype\", \"canopy_cov\", \"fire\", \"date\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "# remove entries with missing values in forest type & canopy cover\n",
    "train_data.dropna(inplace=True)\n",
    "train_data[\"foresttype\"] = train_data.foresttype.astype(\"int\")\n",
    "train_data[\"aspect_categorized\"] = train_data.aspect.apply(convert_aspect_to_cardinal_direction).astype(\"int\")\n",
    "train_data[\"canopy_cover_categorized\"] = train_data.canopy_cov.apply(convert_canopy_cover_to_classes).astype(\"int\")\n",
    "train_data[\"ffmc_categorized\"] = train_data.ffmc.apply(convert_ffmc_to_classes).astype(\"int\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = {\"aspect_groups\": [0, 1, 2, 3, 4, 5, 6, 7], \n",
    "          \"foresttype_groups\": [0, 1, 2, 3, 4, 5, 6], \n",
    "          \"canopy_cover_groups\": [0, 1, 2, 3, 4], \n",
    "          \"ffmc_groups\": [0, 1, 2, 3, 4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data temporally \n",
    "# Older samples (70%) will be used for training; newer samples (30%) will be used for evaluation\n",
    "train_df, test_df = temporal_train_test_split(train_data, \"date\", 0.7)\n",
    "relevant_columns = [\"ffmc\", \"foresttype\", \"aspect_categorized\", \"canopy_cover_categorized\", \"ffmc_categorized\", \"date\"]\n",
    "X_train, y_train = train_df.loc[:, relevant_columns], train_df.loc[:, \"fire\"]\n",
    "X_test, y_test = test_df.loc[:, relevant_columns], test_df.loc[:, \"fire\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train[\"ffmc\"] = scaler.fit_transform(X_train[[\"ffmc\"]])\n",
    "X_test[\"ffmc\"] = scaler.transform(X_test[[\"ffmc\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ffmc_aspect = create_model_ffmc_adjustment_aspect(X_train, y_train, coords)\n",
    "model_ffmc_canopy_cover = create_model_ffmc_adjustment_canopy_cover(X_train, y_train, coords)\n",
    "model_ffmc_forest_type = create_model_ffmc_adjustment_foresttype(X_train, y_train, coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [mu_b1, sigma_b1, intercept, beta_ffmc, error_beta]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='6000' class='' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [6000/6000 05:57&lt;00:00 Sampling 2 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 1_000 tune and 2_000 draw iterations (2_000 + 4_000 draws total) took 408 seconds.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [mu_b1, sigma_b1, intercept, beta_ffmc, error_beta]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='6000' class='' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [6000/6000 20:03&lt;00:00 Sampling 2 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 1_000 tune and 2_000 draw iterations (2_000 + 4_000 draws total) took 1247 seconds.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [mu_b1, sigma_b1, intercept, beta_ffmc, error_beta]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='6000' class='' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [6000/6000 06:13&lt;00:00 Sampling 2 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 1_000 tune and 2_000 draw iterations (2_000 + 4_000 draws total) took 418 seconds.\n"
     ]
    }
   ],
   "source": [
    "with model_ffmc_aspect:\n",
    "    idata_ffmc_aspect = pm.sample(2000, target_accept=0.9, random_seed=0)\n",
    "\n",
    "with model_ffmc_canopy_cover:\n",
    "    idata_ffmc_canopy_cover = pm.sample(2000, target_accept=0.9, random_seed=0)\n",
    "\n",
    "with model_ffmc_forest_type:\n",
    "    idata_ffmc_forest_type = pm.sample(2000, target_accept=0.9, random_seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_diff_pop_group_aspect = idata_ffmc_aspect.posterior.beta_ffmc[0, :] - idata_ffmc_aspect.posterior.mu_b1[0, :]\n",
    "rel_diff_pop_group_aspect = idata_ffmc_aspect.posterior.beta_ffmc[0, :] / idata_ffmc_aspect.posterior.mu_b1[0, :]\n",
    "\n",
    "abs_diff_pop_group_canopy_cover = idata_ffmc_canopy_cover.posterior.beta_ffmc[0, :] - idata_ffmc_canopy_cover.posterior.mu_b1[0, :]\n",
    "rel_diff_pop_group_canopy_cover = idata_ffmc_canopy_cover.posterior.beta_ffmc[0, :] / idata_ffmc_canopy_cover.posterior.mu_b1[0, :]\n",
    "\n",
    "abs_diff_pop_group_forest_type = idata_ffmc_forest_type.posterior.beta_ffmc[0, :] - idata_ffmc_forest_type.posterior.mu_b1[0, :]\n",
    "rel_diff_pop_group_forest_type = idata_ffmc_forest_type.posterior.beta_ffmc[0, :] / idata_ffmc_forest_type.posterior.mu_b1[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only data with location uncertainty < 250m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training data\n",
    "train_data = gpd.read_file(paths[\"training_data\"])\n",
    "train_data = train_data.loc[:, [\"ffmc\", \"aspect\", \"foresttype\", \"canopy_cov\", \"fire\", \"date\", \"Pufferradi\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\b1105474\\AppData\\Local\\Temp\\ipykernel_19772\\1978780342.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fire_samples.Pufferradi = fire_samples.Pufferradi.astype(\"int\")\n"
     ]
    }
   ],
   "source": [
    "# Using only fire samples with low location uncertainty\n",
    "fire_samples = train_data[train_data.fire == 1]\n",
    "non_fire_samples = train_data[train_data.fire == 0]\n",
    "fire_samples.Pufferradi = fire_samples.Pufferradi.astype(\"int\")\n",
    "fire_samples = fire_samples[fire_samples.Pufferradi <= 250]\n",
    "non_fire_samples = non_fire_samples.sample(len(fire_samples))\n",
    "train_data = pd.concat([fire_samples, non_fire_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "# remove entries with missing values in forest type & canopy cover\n",
    "train_data.dropna(subset=(\"foresttype\", \"canopy_cov\"), inplace=True)\n",
    "train_data[\"foresttype\"] = train_data.foresttype.astype(\"int\")\n",
    "train_data[\"aspect_categorized\"] = train_data.aspect.apply(convert_aspect_to_cardinal_direction).astype(\"int\")\n",
    "train_data[\"canopy_cover_categorized\"] = train_data.canopy_cov.apply(convert_canopy_cover_to_classes).astype(\"int\")\n",
    "train_data[\"ffmc_categorized\"] = train_data.ffmc.apply(convert_ffmc_to_classes).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = {\"aspect_groups\": [0, 1, 2, 3, 4, 5, 6, 7], \n",
    "          \"foresttype_groups\": [0, 1, 2, 3, 4, 5, 6], \n",
    "          \"canopy_cover_groups\": [0, 1, 2, 3, 4], \n",
    "          \"ffmc_groups\": [0, 1, 2, 3, 4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data temporally \n",
    "# Older samples (70%) will be used for training; newer samples (30%) will be used for evaluation\n",
    "train_df, test_df = temporal_train_test_split(train_data, \"date\", 0.7)\n",
    "relevant_columns = [\"ffmc\", \"foresttype\", \"aspect_categorized\", \"canopy_cover_categorized\", \"ffmc_categorized\", \"date\"]\n",
    "X_train, y_train = train_df.loc[:, relevant_columns], train_df.loc[:, \"fire\"]\n",
    "X_test, y_test = test_df.loc[:, relevant_columns], test_df.loc[:, \"fire\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train[\"ffmc\"] = scaler.fit_transform(X_train[[\"ffmc\"]])\n",
    "X_test[\"ffmc\"] = scaler.transform(X_test[[\"ffmc\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ffmc_aspect = create_model_ffmc_adjustment_aspect(X_train, y_train, coords)\n",
    "model_ffmc_canopy_cover = create_model_ffmc_adjustment_canopy_cover(X_train, y_train, coords)\n",
    "model_ffmc_forest_type = create_model_ffmc_adjustment_foresttype(X_train, y_train, coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [mu_b1, sigma_b1, intercept, beta_ffmc, error_beta]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='6000' class='' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [6000/6000 03:11&lt;00:00 Sampling 2 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 1_000 tune and 2_000 draw iterations (2_000 + 4_000 draws total) took 232 seconds.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [mu_b1, sigma_b1, intercept, beta_ffmc, error_beta]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='6000' class='' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [6000/6000 13:23&lt;00:00 Sampling 2 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 1_000 tune and 2_000 draw iterations (2_000 + 4_000 draws total) took 824 seconds.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [mu_b1, sigma_b1, intercept, beta_ffmc, error_beta]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='6000' class='' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [6000/6000 04:07&lt;00:00 Sampling 2 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 1_000 tune and 2_000 draw iterations (2_000 + 4_000 draws total) took 268 seconds.\n"
     ]
    }
   ],
   "source": [
    "with model_ffmc_aspect:\n",
    "    idata_ffmc_aspect = pm.sample(2000, target_accept=0.9, random_seed=0)\n",
    "\n",
    "with model_ffmc_canopy_cover:\n",
    "    idata_ffmc_canopy_cover = pm.sample(2000, target_accept=0.9, random_seed=0)\n",
    "\n",
    "with model_ffmc_forest_type:\n",
    "    idata_ffmc_forest_type = pm.sample(2000, target_accept=0.9, random_seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_diff_pop_group_aspect = idata_ffmc_aspect.posterior.beta_ffmc[0, :] - idata_ffmc_aspect.posterior.mu_b1[0, :]\n",
    "rel_diff_pop_group_aspect = idata_ffmc_aspect.posterior.beta_ffmc[0, :] / idata_ffmc_aspect.posterior.mu_b1[0, :]\n",
    "\n",
    "abs_diff_pop_group_canopy_cover = idata_ffmc_canopy_cover.posterior.beta_ffmc[0, :] - idata_ffmc_canopy_cover.posterior.mu_b1[0, :]\n",
    "rel_diff_pop_group_canopy_cover = idata_ffmc_canopy_cover.posterior.beta_ffmc[0, :] / idata_ffmc_canopy_cover.posterior.mu_b1[0, :]\n",
    "\n",
    "abs_diff_pop_group_forest_type = idata_ffmc_forest_type.posterior.beta_ffmc[0, :] - idata_ffmc_forest_type.posterior.mu_b1[0, :]\n",
    "rel_diff_pop_group_forest_type = idata_ffmc_forest_type.posterior.beta_ffmc[0, :] / idata_ffmc_forest_type.posterior.mu_b1[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use forest type, canopy cover & aspect as additional covariates (<250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_all_cov = create_model_ffmc_adjustment_exp2(X_train, y_train, coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m model_all_cov:\n\u001b[1;32m----> 2\u001b[0m     idata_all_cov \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_accept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m save_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../../models/ffmc_adjustment/model_all_cov.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_all_cov, idata_all_cov)\n",
      "File \u001b[1;32mc:\\Users\\b1105474\\AppData\\Local\\miniconda3\\envs\\pymc_env\\Lib\\site-packages\\pymc\\sampling\\mcmc.py:452\u001b[0m, in \u001b[0;36msample\u001b[1;34m(draws, step, init, n_init, initvals, trace, chains, cores, tune, progressbar, model, random_seed, discard_tuned_samples, compute_convergence_checks, callback, jitter_max_retries, return_inferencedata, keep_warning_stat, idata_kwargs, mp_ctx, **kwargs)\u001b[0m\n\u001b[0;32m    449\u001b[0m         auto_nuts_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    451\u001b[0m initial_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 452\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[43massign_step_methods\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTEP_METHODS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(step, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    455\u001b[0m     step \u001b[38;5;241m=\u001b[39m CompoundStep(step)\n",
      "File \u001b[1;32mc:\\Users\\b1105474\\AppData\\Local\\miniconda3\\envs\\pymc_env\\Lib\\site-packages\\pymc\\sampling\\mcmc.py:194\u001b[0m, in \u001b[0;36massign_step_methods\u001b[1;34m(model, step, methods, step_kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m         selected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m    187\u001b[0m             methods,\n\u001b[0;32m    188\u001b[0m             key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m method, var\u001b[38;5;241m=\u001b[39mrv_var, has_gradient\u001b[38;5;241m=\u001b[39mhas_gradient: method\u001b[38;5;241m.\u001b[39m_competence(\n\u001b[0;32m    189\u001b[0m                 var, has_gradient\n\u001b[0;32m    190\u001b[0m             ),\n\u001b[0;32m    191\u001b[0m         )\n\u001b[0;32m    192\u001b[0m         selected_steps[selected]\u001b[38;5;241m.\u001b[39mappend(var)\n\u001b[1;32m--> 194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstantiate_steppers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\b1105474\\AppData\\Local\\miniconda3\\envs\\pymc_env\\Lib\\site-packages\\pymc\\sampling\\mcmc.py:112\u001b[0m, in \u001b[0;36minstantiate_steppers\u001b[1;34m(model, steps, selected_steps, step_kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m         args \u001b[38;5;241m=\u001b[39m step_kwargs\u001b[38;5;241m.\u001b[39mget(step_class\u001b[38;5;241m.\u001b[39mname, {})\n\u001b[0;32m    111\u001b[0m         used_keys\u001b[38;5;241m.\u001b[39madd(step_class\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m--> 112\u001b[0m         step \u001b[38;5;241m=\u001b[39m \u001b[43mstep_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m         steps\u001b[38;5;241m.\u001b[39mappend(step)\n\u001b[0;32m    115\u001b[0m unused_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(step_kwargs)\u001b[38;5;241m.\u001b[39mdifference(used_keys)\n",
      "File \u001b[1;32mc:\\Users\\b1105474\\AppData\\Local\\miniconda3\\envs\\pymc_env\\Lib\\site-packages\\pymc\\step_methods\\hmc\\nuts.py:182\u001b[0m, in \u001b[0;36mNUTS.__init__\u001b[1;34m(self, vars, max_treedepth, early_max_treedepth, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mvars\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, max_treedepth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, early_max_treedepth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    125\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Set up the No-U-Turn sampler.\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;124;03m    `pm.sample` to the desired number of tuning steps.\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_treedepth \u001b[38;5;241m=\u001b[39m max_treedepth\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_max_treedepth \u001b[38;5;241m=\u001b[39m early_max_treedepth\n",
      "File \u001b[1;32mc:\\Users\\b1105474\\AppData\\Local\\miniconda3\\envs\\pymc_env\\Lib\\site-packages\\pymc\\step_methods\\hmc\\base_hmc.py:109\u001b[0m, in \u001b[0;36mBaseHMC.__init__\u001b[1;34m(self, vars, scaling, step_scale, is_cov, model, blocked, potential, dtype, Emax, target_accept, gamma, k, t0, adapt_step_size, step_rand, **pytensor_kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28mvars\u001b[39m \u001b[38;5;241m=\u001b[39m get_value_vars_from_user_vars(\u001b[38;5;28mvars\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model)\n\u001b[1;32m--> 109\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpytensor_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapt_step_size \u001b[38;5;241m=\u001b[39m adapt_step_size\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mEmax \u001b[38;5;241m=\u001b[39m Emax\n",
      "File \u001b[1;32mc:\\Users\\b1105474\\AppData\\Local\\miniconda3\\envs\\pymc_env\\Lib\\site-packages\\pymc\\step_methods\\arraystep.py:166\u001b[0m, in \u001b[0;36mGradientSharedStep.__init__\u001b[1;34m(self, vars, model, blocked, dtype, logp_dlogp_func, **pytensor_kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m model \u001b[38;5;241m=\u001b[39m modelcontext(model)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logp_dlogp_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 166\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogp_dlogp_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpytensor_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m     func \u001b[38;5;241m=\u001b[39m logp_dlogp_func\n",
      "File \u001b[1;32mc:\\Users\\b1105474\\AppData\\Local\\miniconda3\\envs\\pymc_env\\Lib\\site-packages\\pymc\\model.py:648\u001b[0m, in \u001b[0;36mModel.logp_dlogp_function\u001b[1;34m(self, grad_vars, tempered, **kwargs)\u001b[0m\n\u001b[0;32m    642\u001b[0m ip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_point(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    643\u001b[0m extra_vars_and_values \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    644\u001b[0m     var: ip[var\u001b[38;5;241m.\u001b[39mname]\n\u001b[0;32m    645\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_vars\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m input_vars \u001b[38;5;129;01mand\u001b[39;00m var \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m grad_vars\n\u001b[0;32m    647\u001b[0m }\n\u001b[1;32m--> 648\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mValueGradFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcosts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_vars_and_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\b1105474\\AppData\\Local\\miniconda3\\envs\\pymc_env\\Lib\\site-packages\\pymc\\model.py:389\u001b[0m, in \u001b[0;36mValueGradFunction.__init__\u001b[1;34m(self, costs, grad_vars, extra_vars_and_values, dtype, casting, compute_grads, **kwargs)\u001b[0m\n\u001b[0;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m [cost]\n\u001b[0;32m    387\u001b[0m inputs \u001b[38;5;241m=\u001b[39m grad_vars\n\u001b[1;32m--> 389\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pytensor_function \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_pymc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgivens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgivens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\b1105474\\AppData\\Local\\miniconda3\\envs\\pymc_env\\Lib\\site-packages\\pymc\\pytensorf.py:1104\u001b[0m, in \u001b[0;36mcompile_pymc\u001b[1;34m(inputs, outputs, random_seed, mode, **kwargs)\u001b[0m\n\u001b[0;32m   1102\u001b[0m opt_qry \u001b[38;5;241m=\u001b[39m mode\u001b[38;5;241m.\u001b[39mprovided_optimizer\u001b[38;5;241m.\u001b[39mincluding(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_make_inplace\u001b[39m\u001b[38;5;124m\"\u001b[39m, check_parameter_opt)\n\u001b[0;32m   1103\u001b[0m mode \u001b[38;5;241m=\u001b[39m Mode(linker\u001b[38;5;241m=\u001b[39mmode\u001b[38;5;241m.\u001b[39mlinker, optimizer\u001b[38;5;241m=\u001b[39mopt_qry)\n\u001b[1;32m-> 1104\u001b[0m pytensor_function \u001b[38;5;241m=\u001b[39m \u001b[43mpytensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupdates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrng_updates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupdates\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pytensor_function\n",
      "File \u001b[1;32mc:\\Users\\b1105474\\AppData\\Local\\miniconda3\\envs\\pymc_env\\Lib\\site-packages\\pytensor\\compile\\function\\__init__.py:271\u001b[0m, in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    268\u001b[0m source_file \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.pyc?\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;18m__file__\u001b[39m)\n\u001b[0;32m    269\u001b[0m compiled_file \u001b[38;5;241m=\u001b[39m source_file \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 271\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mtb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(stack) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    274\u001b[0m last_frame \u001b[38;5;241m=\u001b[39m stack[idx]\n",
      "File \u001b[1;32mc:\\Users\\b1105474\\AppData\\Local\\miniconda3\\envs\\pymc_env\\Lib\\traceback.py:231\u001b[0m, in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m--> 231\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[1;32mc:\\Users\\b1105474\\AppData\\Local\\miniconda3\\envs\\pymc_env\\Lib\\traceback.py:393\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f, lineno \u001b[38;5;129;01min\u001b[39;00m frame_gen:\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f, (lineno, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_from_extended_frame_gen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextended_frame_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlookup_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapture_locals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapture_locals\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\b1105474\\AppData\\Local\\miniconda3\\envs\\pymc_env\\Lib\\traceback.py:432\u001b[0m, in \u001b[0;36mStackSummary._extract_from_extended_frame_gen\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    428\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(FrameSummary(\n\u001b[0;32m    429\u001b[0m         filename, lineno, name, lookup_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39mf_locals,\n\u001b[0;32m    430\u001b[0m         end_lineno\u001b[38;5;241m=\u001b[39mend_lineno, colno\u001b[38;5;241m=\u001b[39mcolno, end_colno\u001b[38;5;241m=\u001b[39mend_colno))\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[1;32m--> 432\u001b[0m     \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[1;32mc:\\Users\\b1105474\\AppData\\Local\\miniconda3\\envs\\pymc_env\\Lib\\linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m   \u001b[38;5;66;03m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     stat \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(fullname)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     cache\u001b[38;5;241m.\u001b[39mpop(filename, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with model_all_cov:\n",
    "    idata_all_cov = pm.sample(2000, target_accept=0.9, random_seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(\"../../../models/ffmc_adjustment/model_all_cov.pkl\", model_all_cov, idata_all_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_diff_pop_group_aspect = idata_all_cov.posterior.beta_aspect[0, :] - idata_all_cov.posterior.mu_b1[0, :]\n",
    "rel_diff_pop_group_aspect = idata_all_cov.posterior.beta_aspect[0, :] / idata_all_cov.posterior.mu_b1[0, :]\n",
    "\n",
    "abs_diff_pop_group_foresttype = idata_all_cov.posterior.beta_foresttype[0, :] - idata_all_cov.posterior.mu_b2[0, :]\n",
    "rel_diff_pop_group_foresttype = idata_all_cov.posterior.beta_foresttype[0, :] / idata_all_cov.posterior.mu_b2[0, :]\n",
    "\n",
    "abs_diff_pop_group_canopy_cover = idata_all_cov.posterior.beta_canopy_cover[0, :] - idata_all_cov.posterior.mu_b3[0, :]\n",
    "rel_diff_pop_group_canopy_cover = idata_all_cov.posterior.beta_canopy_cover[0, :] / idata_all_cov.posterior.mu_b3[0, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.92482847  6.08290909  9.83965438 -4.74073033 -5.45313243  1.65161698\n",
      "  2.32705053 17.33314128]\n",
      "[0.9294754  0.88480581 0.83056425 1.06081811 1.15476427 0.96500433\n",
      " 1.06257585]\n",
      "[-0.73648449 -0.78196761  1.70983021  1.13866236  0.439639  ]\n"
     ]
    }
   ],
   "source": [
    "print(rel_diff_pop_group_aspect.mean(axis=0).values)\n",
    "print(rel_diff_pop_group_foresttype.mean(axis=0).values)\n",
    "print(rel_diff_pop_group_canopy_cover.mean(axis=0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
