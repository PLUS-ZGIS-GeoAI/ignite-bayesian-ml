{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import shapely\n",
    "import geopandas as gpd\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from config.config import BASE_PATH, PATH_TO_PATH_CONFIG_FILE\n",
    "from src.utils import load_paths_from_yaml, replace_base_path\n",
    "from src.inca_data_extraction import calculate_wind_speed\n",
    "from src.fwi_system_calculator import calculate_ffmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_static_feature_from_raster(events: gpd.GeoDataFrame,\n",
    "                                   path_to_raster: str, feature_name: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\"Adds an additional column to GeoDataFrame with values of raster at same location as point geometries\n",
    "\n",
    "    Args:\n",
    "        path_to_raster (str): path to raster that contains certain feature values (e,g, farmyard density)\n",
    "        feature_name (str): name of feature column in GeoDataFrame\n",
    "        events (gpd.GeoDataFrame): GeoDataFrame containing the date and location of the fire and non-fire events\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: fire and non-fire events with new column for feature values\n",
    "    \"\"\"\n",
    "\n",
    "    with rasterio.open(path_to_raster) as src:\n",
    "        events_updated = events.copy()\n",
    "        coords = list(zip(events.geometry.x, events.geometry.y))\n",
    "        events_updated = events.copy()\n",
    "        events_updated[feature_name] = [x[0] for x in src.sample(coords)]\n",
    "\n",
    "        events_updated.loc[events_updated[feature_name] ==\n",
    "                           src.profile[\"nodata\"], feature_name] = np.nan\n",
    "    return events_updated\n",
    "\n",
    "\n",
    "def get_nearest_pop_value(row) -> float:\n",
    "    \"\"\"choose population data from closest year\n",
    "\n",
    "    Args:\n",
    "        row (str): one row of dataframe\n",
    "\n",
    "    Returns:\n",
    "        float: population number per square km\n",
    "    \"\"\"\n",
    "    year = pd.to_datetime(row.date).year\n",
    "    nearest_year = min([2006, 2011, 2018, 2021], key=lambda x: abs(x-year))\n",
    "    pop_col_name = f\"pop_{nearest_year}\"\n",
    "    return row[pop_col_name]\n",
    "\n",
    "\n",
    "def add_static_features(event_data: gpd.GeoDataFrame, feature_info: dict) -> gpd.GeoDataFrame:\n",
    "    \"\"\"adds static features from rasters to dataframe. \n",
    "\n",
    "    Args:\n",
    "        feature_info (dict): Column names and paths to rasters are defined in feature_info dict\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: dataframe with labels and static features\n",
    "    \"\"\"\n",
    "\n",
    "    for feature_name, rel_feature_layer_path in feature_info:\n",
    "        path_to_feature_layer = os.path.join(BASE_PATH, rel_feature_layer_path)\n",
    "        event_data = add_static_feature_from_raster(\n",
    "            event_data, path_to_feature_layer, feature_name)\n",
    "\n",
    "    # creating population column, with population values closest to event data (drop others)\n",
    "    event_data['pop_dens'] = event_data.apply(\n",
    "        get_nearest_pop_value, axis=1)\n",
    "    event_data = event_data.drop(\n",
    "        [\"pop_2006\", \"pop_2011\", \"pop_2018\", \"pop_2021\"], axis=1)\n",
    "\n",
    "    return event_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load paths from the YAML file\n",
    "paths = load_paths_from_yaml(PATH_TO_PATH_CONFIG_FILE)\n",
    "paths = replace_base_path(paths, BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fire event dataset\n",
    "event_data = gpd.read_file(paths[\"fire_events\"][\"final\"])\n",
    "event_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = paths[\"inca\"][\"training_data\"]\n",
    "\n",
    "# Create an empty list to store extracted data\n",
    "data_list = []\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Use regular expression to extract ID and JSON content\n",
    "        match = re.match(r'(\\d+)(\\{.+})', line)\n",
    "        if match:\n",
    "            numeric_id = int(match.group(1))\n",
    "            json_data = json.loads(match.group(2))\n",
    "\n",
    "            # Extract required information from JSON\n",
    "            last_timestamp = json_data[\"timestamps\"][-1]\n",
    "            last_T2M = json_data[\"features\"][0][\"properties\"][\"parameters\"][\"T2M\"][\"data\"][-1]\n",
    "            last_RH2M = json_data[\"features\"][0][\"properties\"][\"parameters\"][\"RH2M\"][\"data\"][-1]\n",
    "            last_UU = json_data[\"features\"][0][\"properties\"][\"parameters\"][\"UU\"][\"data\"][-1]\n",
    "            last_VV = json_data[\"features\"][0][\"properties\"][\"parameters\"][\"VV\"][\"data\"][-1]\n",
    "\n",
    "            # Extract RR data and check if it contains only NaN\n",
    "            rr_data = json_data[\"features\"][0][\"properties\"][\"parameters\"][\"RR\"][\"data\"]\n",
    "            if any(val is None for val in rr_data):\n",
    "                sum_RR = None\n",
    "            else:\n",
    "                sum_RR = np.sum(rr_data)\n",
    "\n",
    "            # Extract coordinates\n",
    "            coordinates = json_data[\"features\"][0][\"geometry\"][\"coordinates\"]\n",
    "            point = shapely.Point(coordinates)\n",
    "\n",
    "            # Append data to the list\n",
    "            data_list.append({\n",
    "                \"ID\": numeric_id,\n",
    "                \"Timestamp\": last_timestamp,\n",
    "                \"T2M\": last_T2M,\n",
    "                \"RH2M\": last_RH2M,\n",
    "                \"UU\": last_UU,\n",
    "                \"VV\": last_VV,\n",
    "                \"RR_sum_24h\": sum_RR,\n",
    "                \"geometry\": point\n",
    "            })\n",
    "\n",
    "# Create a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(data_list, geometry='geometry', crs=\"EPSG:4326\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate windspeed and FFMC\n",
    "gdf.dropna(inplace=True)\n",
    "gdf[\"windspeed\"] = gdf.apply(lambda row: calculate_wind_speed(row[\"UU\"], row[\"VV\"]), axis=1)\n",
    "gdf[\"ffmc\"] = gdf.apply(lambda row:  calculate_ffmc(85, row[\"RH2M\"], row[\"T2M\"], row[\"RR_sum_24h\"], row[\"windspeed\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join ffmc with fire event data\n",
    "train_data = pd.merge(event_data, gdf, left_on=\"index\", right_on=\"ID\")\n",
    "train_data = train_data.loc[:, [\"date\", \"Pufferradi\", \"fire\", \"ffmc\", \"geometry_x\"]]\n",
    "train_data.rename(columns={\"geometry_x\": \"geometry\"}, inplace=True)\n",
    "train_data = gpd.GeoDataFrame(train_data, geometry=\"geometry\", crs=\"EPSG:31287\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add static features\n",
    "feature_info = [\n",
    "    (\"pop_2006\", paths[\"population_layers\"][\"2006\"][\"final\"]),\n",
    "    (\"pop_2011\", paths[\"population_layers\"][\"2011\"][\"final\"]),\n",
    "    (\"pop_2018\", paths[\"population_layers\"][\"2018\"][\"final\"]),\n",
    "    (\"pop_2021\", paths[\"population_layers\"][\"2021\"][\"final\"]),\n",
    "    (\"farmyard_ds\", paths[\"farmyard_density\"][\"final\"]),\n",
    "    (\"hiking_ds\", paths[\"roads\"][\"hikingtrails\"][\"final\"]),\n",
    "    (\"forest_ds\", paths[\"roads\"][\"forestroads\"][\"final\"]),\n",
    "    (\"rail_dens\", paths[\"railways\"][\"final\"]),\n",
    "    (\"elevation\", paths[\"topographical_layers\"][\"elevation\"][\"final\"]),\n",
    "    (\"slope\", paths[\"topographical_layers\"][\"slope\"][\"final\"]),\n",
    "    (\"aspect\", paths[\"topographical_layers\"][\"aspect\"][\"final\"]),\n",
    "    (\"foresttype\", paths[\"forest_type\"][\"final\"])\n",
    "]\n",
    "\n",
    "train_data = add_static_features(train_data, feature_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    744\n",
       "0    177\n",
       "Name: fire, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.fire.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\AppData\\Local\\Temp;\\ipykernel_18852\\3100948911.py:1: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  train_data.to_file(paths[\"training_data\"][\"subset\"])\n"
     ]
    }
   ],
   "source": [
    "train_data.to_file(paths[\"training_data\"][\"subset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "pymc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
